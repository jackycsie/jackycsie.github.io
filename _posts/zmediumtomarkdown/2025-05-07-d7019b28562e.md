---
title: "用 Python 導入 Google Gemini API 自動整理 AWS 架構部落格到 Notion"
author: "黃馨平"
date: 2025-05-07T04:43:41.349+0000
last_modified_at: 2025-05-07T11:41:17.611+0000
categories: [""]
tags: ["google-gemini","aws","notion","python"]
description: "自動化整理 AWS 架構文章"
image:
  path: /assets/d7019b28562e/1*f-DQ19ADH3JoW4F0njbMVg.png
render_with_liquid: false
---

### **用** Python 導入 Google Gemini **API 自動整理 AWS 架構部落格到 Notion**


![](/assets/d7019b28562e/1*f-DQ19ADH3JoW4F0njbMVg.png)


由於近期在準備一些 SA 的東西，想說如果只是單玩這些 AWS 的個別服務有點覺得好像沒有很架構的感覺，因此想說看看我們 AWS 的架構師，他們在做各項不同產業的應用的時候，他們的思維模式與考慮的服務會是什麼。

但每天自己去點這些文章很麻煩，然後也沒辦法做筆記，因此想說透過自動化的方式，讓 AWS 相關的文章可以自動存到 notion 中。

但剛開始這一步完成的時候，就在思考，有沒有一種方法，可以快速的讓我簡單知道這篇文章有不有趣，以及他通常會用到什麼類型的 service ，因此我就去網路 survey 了一下，發現 Google Gemini 有支援免費的 API 可以 call 因此，我就想說，那我把資料撈進來以後，先請 AI 幫我總結一下並且跟我說有什麼 tag ，這樣我在念 SA 相關的文章的時候就可以更快速了，然後也不會像研究所一樣唸完了整篇 Paper 才發現這篇好像沒啥用 ＸＤＤ

另外我這次追蹤的 AWS RSS 有這 4 個
```bash
https://aws.amazon.com/blogs/architecture/feed/
https://aws.amazon.com/blogs/machine-learning/feed/
https://aws.amazon.com/blogs/developer/feed/
https://aws.amazon.com/blogs/aws/feed/
```

下面是我的流程。
1. 建立一個 Notion 資料庫來存文章摘要
2. 用 Python 撰寫 RSS 抓文工具\(並且包含去重複\)
3. 使用 Google Gemini API 自動產出摘要與標籤
4. 自動上傳到 Notion，並支援卡片式封面顯示

### 步驟一：建立 Notion 資料庫
1. 建一個名為 `AWS Architecture Feed` 的 Database
2. 加入以下欄位：

- `Title` （標題，type: title）
- `URL` （文章連結，type: url）
- `Date` （發文日期，type: date）
- `Summary` （AI 總結，type: rich\_text）
- `AI_Tag` （標籤，type: multi\-select）



![](/assets/d7019b28562e/1*El4gioYAN6SryuH5vBMt3w.png)


3\. 建立 [Notion Integration](https://www.notion.so/profile/integrations/){:target="_blank"} 並取得 `Internal Integration Token`


![](/assets/d7019b28562e/1*09oxD_vn9xksT1SNL6TOig.png)


4\. 邀請這個 Integration 成為資料庫協作者


![](/assets/d7019b28562e/1*IfgMIxpdPegJrLAxoYDBRQ.png)


上述步驟做完後，記得把 Notion Integration token 與 Notion database ID 都記起來等等會用到。
### 步驟二：拿到 Google Gemini 的 API Key\.


[![取得Gemini API key](/assets/d7019b28562e/2e38_hqdefault.jpg "取得Gemini API key")](https://www.youtube.com/watch?v=VEdnpjUrmjM){:target="_blank"}

### 步驟三：Python 環境配置

下面是這次需要使用到的 python package\.
```shell
$ cat requirements.txt

feedparser
notion-client
python-dotenv
google-generativeai
newspaper3k
lxml
lxml-html-clean
```

接著設定我們的環境變數
```makefile
$ cat .env

NOTION_TOKEN=your_notion_token
DATABASE_ID=your_database_id
GOOGLE_API_KEY=your_google_api_key
```

最後程式碼如下
```py
import os
import re
import time
import feedparser
import google.generativeai as genai
from dotenv import load_dotenv
from datetime import datetime, timezone
from notion_client import Client
from newspaper import Article

# === 環境變數設定 ===
load_dotenv()
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
DATABASE_ID = os.getenv("DATABASE_ID")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# === 初始化服務 ===
notion = Client(auth=NOTION_TOKEN)
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel("models/gemini-2.0-flash")

# === RSS Feed 資源 ===
FEED_URLS = [
    "https://aws.amazon.com/blogs/architecture/feed/",
    "https://aws.amazon.com/blogs/machine-learning/feed/",
    "https://aws.amazon.com/blogs/developer/feed/",
    "https://aws.amazon.com/blogs/aws/feed/",
]

PROCESSED_FILE = "processed.txt"
MAX_ARTICLES = 10
DAY_LIMIT = 3

def load_processed_urls():
    if not os.path.exists(PROCESSED_FILE):
        return set()
    with open(PROCESSED_FILE, "r") as f:
        return set(line.strip() for line in f)

def save_processed_url(url):
    with open(PROCESSED_FILE, "a") as f:
        f.write(url + "\n")

def extract_article_text_and_image(url):
    try:
        article = Article(url)
        article.download()
        article.parse()
        return article.text, article.top_image if article.top_image else None
    except Exception as e:
        print(f" 抓文章失敗：{url} - {e}")
        return "", None

def get_summary_and_tags(text):
    prompt = f"""
你是一位熟悉 AWS 架構的技術顧問，請閱讀以下文章內容並用繁體中文完成：

1. 用一句話摘要本篇文章的重點（繁體中文，避免出現'本文'、'摘要'等開頭）
2. 回傳 2–4 個分類標籤（僅英文單字，用半形逗號分隔，不要加項目符號）

文章：\n{text[:4000]}
"""
    try:
        response = model.generate_content(prompt)
        if not hasattr(response, "text") or not response.text.strip():
            return "", []

        result = response.text.strip()
        lines = result.splitlines()
        summary = ""
        tags = []

        for line in lines:
            line = re.sub(r"^\d+\.\s*", "", line.strip())
            if not summary and re.search(r'[\u4e00-\u9fff]', line):
                summary = line.strip()
            elif "," in line:
                tags = [t.strip() for t in line.split(",") if t.strip()]
                break

        return summary, tags[:4]

    except Exception as e:
        if "429" in str(e):
            print("⏳ Gemini 限速，等兩分鐘重試...")
            time.sleep(120)
            return get_summary_and_tags(text)
        print(f" Gemini 失敗：{e}")
        return "", []

def create_notion_item(entry, summary, tags, cover_image):
    title = entry.title
    url = entry.link
    
    pub_date = datetime(*entry.published_parsed[:6]).replace(tzinfo=timezone.utc)

    properties = {
        "Title": {"title": [{"text": {"content": title}}]},
        "URL": {"url": url},
        "Date": {"date": {"start": pub_date.isoformat()}},
        "Summary": {"rich_text": [{"text": {"content": summary}}]},
        "AI_Tag": {"multi_select": [{"name": tag} for tag in tags]}
    }

    page_data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": properties
    }

    if cover_image:
        page_data["cover"] = {"type": "external", "external": {"url": cover_image}}

    try:
        notion.pages.create(**page_data)
        print(f"寫入完成：{title}")
    except Exception as e:
        print(f"寫入失敗：{title} - {e}")

# === 主程式 ===
def main():
    now = datetime.now(timezone.utc)
    processed = load_processed_urls()
    count = 0

    for feed_url in FEED_URLS:
        feed = feedparser.parse(feed_url)
        print(f"來源：{feed_url}，共 {len(feed.entries)} 篇")

        for entry in feed.entries:
            if count >= MAX_ARTICLES:
                return

            pub_date = datetime(*entry.published_parsed[:6]).replace(tzinfo=timezone.utc)
            if (now - pub_date).days > DAY_LIMIT:
                continue

            if entry.link in processed:
                continue

            print(f"\n分析文章：{entry.title}")
            article_text, cover_image = extract_article_text_and_image(entry.link)
            if not article_text:
                continue

            summary, tags = get_summary_and_tags(article_text)
            if not summary:
                print(f"略過：Gemini 無法生成內容：{entry.title}")
                continue

            print(f"摘要：{summary}")
            print(f"分類：{tags}")
            create_notion_item(entry, summary, tags, cover_image)
            save_processed_url(entry.link)
            count += 1
            time.sleep(3)

if __name__ == "__main__":
    main()
```

最後透過 Python 存下來的內容是這樣


![](/assets/d7019b28562e/1*Y-gNaNWa0wOdaRkcJjMJOg.png)


但因為上述太醜了可以用成圖庫的方法比較好懂。


![](/assets/d7019b28562e/1*7ZRtQcSsA9C9qhx0DbHgPQ.png)


最後，Google Gemini Call API 雖然是免費的，但還是有次數限制的。

例如 Gemini 2\.0 Flash 的內容如下。

更多細節可以參考網址：
- [https://aistudio\.google\.com/app/plan\_information](https://aistudio.google.com/app/plan_information){:target="_blank"}
- [https://ai\.google\.dev/gemini\-api/docs/rate\-limits?hl=zh\-tw](https://ai.google.dev/gemini-api/docs/rate-limits?hl=zh-tw){:target="_blank"}
- 每分鐘要求數 \( **RPM** \)
- 每日要求配額 \( **RPD** \)
- 每分鐘符記數 \( **TPM** \)



![](/assets/d7019b28562e/1*-F4X7E0VoQeJG9EfGkD2Rg.png)


之後我就可以先對我有興趣的 AWS 文章做筆記開始念，然後把沒興趣的文章就刪掉 ＸＤＤ


![](/assets/d7019b28562e/1*z1_Mff9-yI4pcYFcNsCuuA.png)

### 結束

今天分享的小工具大概就這樣，謝謝大家，有其他有趣的小工具在請各位大大分享囉。


![](/assets/d7019b28562e/1*_gRBk3wzEg06TDyYS6Nlhw.jpeg)




_[Post](https://medium.com/@jackycsie/%E7%94%A8-python-%E5%B0%8E%E5%85%A5-google-gemini-api-%E8%87%AA%E5%8B%95%E6%95%B4%E7%90%86-aws-%E6%9E%B6%E6%A7%8B%E9%83%A8%E8%90%BD%E6%A0%BC%E5%88%B0-notion-d7019b28562e){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
